{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1female\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebookname=os.path.splitext(nb_name)[0]\n",
    "genderindex = [0,0]\n",
    "print(notebookname)\n",
    "if notebookname.find('female'):\n",
    "    genderchar = 'F'\n",
    "    genderindex[0] = 0\n",
    "    genderindex[1] = 2\n",
    "elif notebookname.find('male'):\n",
    "    genderchar = 'M'\n",
    "    genderindex[0] = 0\n",
    "    genderindex[1] = 3\n",
    "else: \n",
    "    print('Error!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(genderindex[0]), str(genderindex[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read labels and filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traindf[\"0\"] to [\"9\"] contains the PC values, \n",
    "traindf[\"name\"] contains the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('labels/'+genderchar+'train_labels.csv') \n",
    "validdf = pd.read_csv('labels/'+genderchar+'val_labels.csv')\n",
    "testdf  = pd.read_csv('labels/'+genderchar+'test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPRING1062_0001.jpg'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validdf['name'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up data generators \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21210 validated image filenames.\n",
      "Found 6060 validated image filenames.\n",
      "Found 6060 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory='dataset/'+genderchar+'train',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=validdf,\n",
    "    directory='dataset/'+genderchar+'val',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "test_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=testdf,\n",
    "    directory='dataset/'+genderchar+'test',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n// test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 448, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 56, 64)  0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 56, 64)  4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 56, 64)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 56, 64)  0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 56, 256) 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 56, 256) 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 56, 256) 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 56, 64)  16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 56, 64)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 56, 64)  0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 56, 256) 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 56, 256) 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 56, 64)  16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 56, 64)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 56, 64)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 56, 256) 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 56, 256) 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 7, 512)   524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 7, 512)   0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 7, 512)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 7, 2048)  2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 7, 2048)  0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 7, 2048)  0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 7, 512)   1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 7, 512)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 7, 512)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 7, 2048)  0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 7, 2048)  0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 7, 512)   1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 7, 512)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 7, 512)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 7, 2048)  0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 7, 2048)  0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# uncomment for training resnet50\n",
    "#get resnet50\n",
    "model_fn=ResNet50(include_top=False, input_shape=(448,224,3),pooling='avg')\n",
    "#for layer in model_fn.layers:\n",
    "#    layer.trainable = False\n",
    "model_fn.summary()\n",
    "\n",
    "# uncomment for training inceptionv3\n",
    "#model_fn=InceptionV3(include_top=False, input_shape=(448,224,1),pooling='avg')\n",
    "#model_fn.summary()\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(model_fn)\n",
    "#model.add(L.Dense(256,activation='relu'))\n",
    "model.add(L.Dense(2,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2121 steps, validate for 606 steps\n",
      "Epoch 1/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.6460 - mean_absolute_error: 0.8959\n",
      "Epoch 00001: val_loss improved from inf to 27.85214, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 340s 160ms/step - loss: 1.6456 - mean_absolute_error: 0.8958 - val_loss: 27.8521 - val_mean_absolute_error: 4.1969\n",
      "Epoch 2/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.7436 - mean_absolute_error: 0.6382\n",
      "Epoch 00002: val_loss did not improve from 27.85214\n",
      "2121/2121 [==============================] - 314s 148ms/step - loss: 0.7435 - mean_absolute_error: 0.6382 - val_loss: 299.6952 - val_mean_absolute_error: 13.5498\n",
      "Epoch 3/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.4994 - mean_absolute_error: 0.5279\n",
      "Epoch 00003: val_loss improved from 27.85214 to 1.92760, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 339s 160ms/step - loss: 0.4993 - mean_absolute_error: 0.5278 - val_loss: 1.9276 - val_mean_absolute_error: 1.0830\n",
      "Epoch 4/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.3341 - mean_absolute_error: 0.4364\n",
      "Epoch 00004: val_loss did not improve from 1.92760\n",
      "2121/2121 [==============================] - 315s 149ms/step - loss: 0.3340 - mean_absolute_error: 0.4364 - val_loss: 2.2300 - val_mean_absolute_error: 1.1259\n",
      "Epoch 5/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.2265 - mean_absolute_error: 0.3590\n",
      "Epoch 00005: val_loss did not improve from 1.92760\n",
      "2121/2121 [==============================] - 316s 149ms/step - loss: 0.2265 - mean_absolute_error: 0.3590 - val_loss: 161.3124 - val_mean_absolute_error: 12.1706\n",
      "Epoch 6/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.1877 - mean_absolute_error: 0.3208\n",
      "Epoch 00006: val_loss improved from 1.92760 to 0.95273, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 343s 162ms/step - loss: 0.1876 - mean_absolute_error: 0.3208 - val_loss: 0.9527 - val_mean_absolute_error: 0.7155\n",
      "Epoch 7/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.1696 - mean_absolute_error: 0.2945\n",
      "Epoch 00007: val_loss did not improve from 0.95273\n",
      "2121/2121 [==============================] - 319s 150ms/step - loss: 0.1696 - mean_absolute_error: 0.2945 - val_loss: 1.4346 - val_mean_absolute_error: 0.9137\n",
      "Epoch 8/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0901 - mean_absolute_error: 0.2290\n",
      "Epoch 00008: val_loss did not improve from 0.95273\n",
      "2121/2121 [==============================] - 319s 150ms/step - loss: 0.0901 - mean_absolute_error: 0.2290 - val_loss: 1.5763 - val_mean_absolute_error: 0.9853\n",
      "Epoch 9/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0738 - mean_absolute_error: 0.2098\n",
      "Epoch 00009: val_loss did not improve from 0.95273\n",
      "2121/2121 [==============================] - 319s 151ms/step - loss: 0.0737 - mean_absolute_error: 0.2098 - val_loss: 295.6066 - val_mean_absolute_error: 16.8491\n",
      "Epoch 10/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.1986\n",
      "Epoch 00010: val_loss improved from 0.95273 to 0.90018, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 344s 162ms/step - loss: 0.0685 - mean_absolute_error: 0.1986 - val_loss: 0.9002 - val_mean_absolute_error: 0.6804\n",
      "Epoch 11/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0574 - mean_absolute_error: 0.1838\n",
      "Epoch 00011: val_loss did not improve from 0.90018\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 0.0573 - mean_absolute_error: 0.1838 - val_loss: 1.4867 - val_mean_absolute_error: 0.9560\n",
      "Epoch 12/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0448 - mean_absolute_error: 0.1617\n",
      "Epoch 00012: val_loss did not improve from 0.90018\n",
      "2121/2121 [==============================] - 323s 152ms/step - loss: 0.0448 - mean_absolute_error: 0.1617 - val_loss: 3.2570 - val_mean_absolute_error: 1.4335\n",
      "Epoch 13/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0488 - mean_absolute_error: 0.1656\n",
      "Epoch 00013: val_loss did not improve from 0.90018\n",
      "2121/2121 [==============================] - 325s 153ms/step - loss: 0.0488 - mean_absolute_error: 0.1656 - val_loss: 1.5088 - val_mean_absolute_error: 0.9305\n",
      "Epoch 14/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0836 - mean_absolute_error: 0.1790\n",
      "Epoch 00014: val_loss did not improve from 0.90018\n",
      "2121/2121 [==============================] - 326s 154ms/step - loss: 0.0836 - mean_absolute_error: 0.1790 - val_loss: 3.4744 - val_mean_absolute_error: 1.3737\n",
      "Epoch 15/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1364\n",
      "Epoch 00015: val_loss did not improve from 0.90018\n",
      "2121/2121 [==============================] - 326s 154ms/step - loss: 0.0362 - mean_absolute_error: 0.1364 - val_loss: 0.9237 - val_mean_absolute_error: 0.7255\n",
      "Epoch 16/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.0724\n",
      "Epoch 00016: val_loss improved from 0.90018 to 0.72528, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 351s 165ms/step - loss: 0.0089 - mean_absolute_error: 0.0724 - val_loss: 0.7253 - val_mean_absolute_error: 0.6103\n",
      "Epoch 17/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0573\n",
      "Epoch 00017: val_loss did not improve from 0.72528\n",
      "2121/2121 [==============================] - 326s 154ms/step - loss: 0.0054 - mean_absolute_error: 0.0573 - val_loss: 0.7499 - val_mean_absolute_error: 0.6293\n",
      "Epoch 18/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0495\n",
      "Epoch 00018: val_loss did not improve from 0.72528\n",
      "2121/2121 [==============================] - 326s 154ms/step - loss: 0.0040 - mean_absolute_error: 0.0495 - val_loss: 0.7418 - val_mean_absolute_error: 0.6207\n",
      "Epoch 19/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0439\n",
      "Epoch 00019: val_loss improved from 0.72528 to 0.71972, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 340s 160ms/step - loss: 0.0031 - mean_absolute_error: 0.0439 - val_loss: 0.7197 - val_mean_absolute_error: 0.6093\n",
      "Epoch 20/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0389\n",
      "Epoch 00020: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 315s 148ms/step - loss: 0.0025 - mean_absolute_error: 0.0389 - val_loss: 0.7490 - val_mean_absolute_error: 0.6174\n",
      "Epoch 21/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0358\n",
      "Epoch 00021: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 315s 149ms/step - loss: 0.0021 - mean_absolute_error: 0.0358 - val_loss: 0.7268 - val_mean_absolute_error: 0.6082\n",
      "Epoch 22/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0322\n",
      "Epoch 00022: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 315s 148ms/step - loss: 0.0017 - mean_absolute_error: 0.0322 - val_loss: 0.7235 - val_mean_absolute_error: 0.6065\n",
      "Epoch 23/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0300\n",
      "Epoch 00023: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 315s 149ms/step - loss: 0.0015 - mean_absolute_error: 0.0300 - val_loss: 0.7423 - val_mean_absolute_error: 0.6208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0274\n",
      "Epoch 00024: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 0.0012 - mean_absolute_error: 0.0274 - val_loss: 0.7223 - val_mean_absolute_error: 0.6073\n",
      "Epoch 25/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 6.1779e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 00025: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 6.1775e-04 - mean_absolute_error: 0.0194 - val_loss: 0.7219 - val_mean_absolute_error: 0.6070\n",
      "Epoch 26/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 5.0301e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 00026: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 5.0290e-04 - mean_absolute_error: 0.0176 - val_loss: 0.7286 - val_mean_absolute_error: 0.6083\n",
      "Epoch 27/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.5758e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 00027: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 4.5762e-04 - mean_absolute_error: 0.0168 - val_loss: 0.7229 - val_mean_absolute_error: 0.6074\n",
      "Epoch 28/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.2723e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 00028: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 4.2722e-04 - mean_absolute_error: 0.0162 - val_loss: 0.7217 - val_mean_absolute_error: 0.6069\n",
      "Epoch 29/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.0305e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 00029: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 4.0305e-04 - mean_absolute_error: 0.0157 - val_loss: 0.7219 - val_mean_absolute_error: 0.6073\n",
      "Epoch 30/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.7920e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 00030: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 3.7941e-04 - mean_absolute_error: 0.0153 - val_loss: 0.7216 - val_mean_absolute_error: 0.6060\n",
      "Epoch 31/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.6234e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 00031: val_loss did not improve from 0.71972\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 3.6232e-04 - mean_absolute_error: 0.0149 - val_loss: 0.7259 - val_mean_absolute_error: 0.6071\n",
      "Epoch 32/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.4560e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 00032: val_loss improved from 0.71972 to 0.71949, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 334s 158ms/step - loss: 3.4554e-04 - mean_absolute_error: 0.0146 - val_loss: 0.7195 - val_mean_absolute_error: 0.6058\n",
      "Epoch 33/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.2919e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 00033: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 3.2922e-04 - mean_absolute_error: 0.0142 - val_loss: 0.7207 - val_mean_absolute_error: 0.6066\n",
      "Epoch 34/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.1361e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 00034: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 3.1369e-04 - mean_absolute_error: 0.0139 - val_loss: 0.7228 - val_mean_absolute_error: 0.6075\n",
      "Epoch 35/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.0010e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 00035: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 3.0003e-04 - mean_absolute_error: 0.0136 - val_loss: 0.7233 - val_mean_absolute_error: 0.6079\n",
      "Epoch 36/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.8867e-04 - mean_absolute_error: 0.0133\n",
      "Epoch 00036: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 2.8869e-04 - mean_absolute_error: 0.0133 - val_loss: 0.7238 - val_mean_absolute_error: 0.6076\n",
      "Epoch 37/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.7513e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 00037: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 2.7526e-04 - mean_absolute_error: 0.0130 - val_loss: 0.7214 - val_mean_absolute_error: 0.6069\n",
      "Epoch 38/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.6407e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00038: val_loss did not improve from 0.71949\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 2.6406e-04 - mean_absolute_error: 0.0127 - val_loss: 0.7202 - val_mean_absolute_error: 0.6073\n",
      "Epoch 39/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.5350e-04 - mean_absolute_error: 0.0124\n",
      "Epoch 00039: val_loss improved from 0.71949 to 0.71881, saving model to models/checkpoint_CNN1female\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1female/assets\n",
      "2121/2121 [==============================] - 334s 158ms/step - loss: 2.5357e-04 - mean_absolute_error: 0.0124 - val_loss: 0.7188 - val_mean_absolute_error: 0.6063\n",
      "Epoch 40/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.4184e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00040: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 2.4180e-04 - mean_absolute_error: 0.0121 - val_loss: 0.7216 - val_mean_absolute_error: 0.6074\n",
      "Epoch 41/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.3355e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 00041: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 2.3358e-04 - mean_absolute_error: 0.0119 - val_loss: 0.7235 - val_mean_absolute_error: 0.6071\n",
      "Epoch 42/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.2270e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00042: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 2.2273e-04 - mean_absolute_error: 0.0116 - val_loss: 0.7234 - val_mean_absolute_error: 0.6076\n",
      "Epoch 43/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.1247e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 00043: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 2.1247e-04 - mean_absolute_error: 0.0114 - val_loss: 0.7241 - val_mean_absolute_error: 0.6074\n",
      "Epoch 44/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.0583e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 00044: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 2.0579e-04 - mean_absolute_error: 0.0112 - val_loss: 0.7260 - val_mean_absolute_error: 0.6082\n",
      "Epoch 45/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.9521e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00045: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 1.9520e-04 - mean_absolute_error: 0.0109 - val_loss: 0.7247 - val_mean_absolute_error: 0.6079\n",
      "Epoch 46/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.8713e-04 - mean_absolute_error: 0.0107\n",
      "Epoch 00046: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 1.8716e-04 - mean_absolute_error: 0.0107 - val_loss: 0.7242 - val_mean_absolute_error: 0.6078\n",
      "Epoch 47/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.7978e-04 - mean_absolute_error: 0.0104\n",
      "Epoch 00047: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 1.7973e-04 - mean_absolute_error: 0.0104 - val_loss: 0.7201 - val_mean_absolute_error: 0.6064\n",
      "Epoch 48/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.7100e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 00048: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 1.7104e-04 - mean_absolute_error: 0.0102 - val_loss: 0.7229 - val_mean_absolute_error: 0.6080\n",
      "Epoch 49/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.6464e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 00049: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 309s 146ms/step - loss: 1.6464e-04 - mean_absolute_error: 0.0100 - val_loss: 0.7210 - val_mean_absolute_error: 0.6067\n",
      "Epoch 50/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.5739e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 00050: val_loss did not improve from 0.71881\n",
      "2121/2121 [==============================] - 310s 146ms/step - loss: 1.5744e-04 - mean_absolute_error: 0.0097 - val_loss: 0.7201 - val_mean_absolute_error: 0.6068\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.00001, min_delta=0.001)\n",
    "ckpt=ModelCheckpoint('models/checkpoint_'+notebookname, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.0001)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mean_absolute_error'])\n",
    "\n",
    "# model fit call for all data\n",
    "# history=model.fit(train, train_label, batch_size=32,\n",
    "#                     steps_per_epoch=len(train) / 32, epochs=50)\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                           steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                           validation_data=valid_generator,\n",
    "                           validation_steps=STEP_SIZE_VALID,\n",
    "                           validation_freq=1,\n",
    "                           epochs=50,\n",
    "                           callbacks=[rlr,ckpt,es])\n",
    "# model fit call with validation\n",
    "#history=model.fit(X_train, y_train,validation_data=(X_val,y_val), batch_size=64,\n",
    "#                    steps_per_epoch=len(X_train) / 64,validation_steps=len(X_val)/64, epochs=50,callbacks=[rlr,ckpt,es])\n",
    "\n",
    "# save weights\n",
    "model.save_weights('models/'+notebookname+'.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-51-e82515759ac2>:4: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "606/606 [==============================] - 26s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "predictions=model.predict_generator(test_generator,\n",
    "                                    steps=STEP_SIZE_TEST,\n",
    "                                    verbose = 1)\n",
    "data = {'T1': testdf[str(genderindex[0])],\n",
    "        'T2': testdf[str(genderindex[1])],\n",
    "        'P1': predictions[:,0],\n",
    "        'P2': predictions[:,1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "import csv\n",
    "\n",
    "df.to_csv('results/test_results_'+notebookname+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy'+notebookname)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
