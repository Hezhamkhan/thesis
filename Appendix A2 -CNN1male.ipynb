{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1male\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebookname=os.path.splitext(nb_name)[0]\n",
    "genderindex = [0,0]\n",
    "print(notebookname)\n",
    "if notebookname.find('female')>0:\n",
    "    genderchar = 'F'\n",
    "    genderindex[0] = 0\n",
    "    genderindex[1] = 2\n",
    "elif notebookname.find('male')>0:\n",
    "    genderchar = 'M'\n",
    "    genderindex[0] = 0\n",
    "    genderindex[1] = 3\n",
    "else: \n",
    "    print('Error!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(genderindex[0]), str(genderindex[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read labels and filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traindf[\"0\"] to [\"9\"] contains the PC values, \n",
    "traindf[\"name\"] contains the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('labels/'+genderchar+'train_labels.csv') \n",
    "validdf = pd.read_csv('labels/'+genderchar+'val_labels.csv')\n",
    "testdf  = pd.read_csv('labels/'+genderchar+'test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPRING0653_0001.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validdf['name'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up data generators \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21210 validated image filenames.\n",
      "Found 6060 validated image filenames.\n",
      "Found 6060 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory='dataset/'+genderchar+'train',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=validdf,\n",
    "    directory='dataset/'+genderchar+'val',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode='raw',\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "test_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=testdf,\n",
    "    directory='dataset/'+genderchar+'test',\n",
    "    x_col='name',\n",
    "    y_col=[str(genderindex[0]), str(genderindex[1])],\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(224,448)\n",
    "    #color_mode=\"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n// test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 448, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 454, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 224, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 224, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 224, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 226, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 112, 56, 64)  0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 112, 56, 64)  4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 112, 56, 64)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 112, 56, 64)  0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 112, 56, 256) 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 112, 56, 256) 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 112, 56, 256) 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 112, 56, 64)  16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 112, 56, 64)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 112, 56, 64)  0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 112, 56, 256) 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 112, 56, 256) 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 112, 56, 64)  16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 112, 56, 64)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 112, 56, 64)  36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 112, 56, 64)  256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 112, 56, 64)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 112, 56, 256) 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 112, 56, 256) 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 112, 56, 256) 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 112, 56, 256) 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 56, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 56, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 56, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 56, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 56, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 56, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 56, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 56, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 56, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 56, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 56, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 56, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 56, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 56, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 56, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 56, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 56, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 56, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 56, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 56, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 56, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 56, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 56, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 28, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 28, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 28, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 28, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 28, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 28, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 28, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 28, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 28, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 28, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 28, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 28, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 28, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 28, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 28, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 28, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 28, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 28, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 28, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 28, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 28, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 28, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 28, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 28, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 28, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 28, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 28, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 28, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 28, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 28, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 28, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 14, 7, 512)   524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 14, 7, 512)   0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 14, 7, 512)   0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 14, 7, 2048)  2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 14, 7, 2048)  0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 14, 7, 2048)  0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 14, 7, 512)   1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 14, 7, 512)   0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 14, 7, 512)   0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 14, 7, 2048)  0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 14, 7, 2048)  0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 14, 7, 512)   1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 14, 7, 512)   0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 14, 7, 512)   2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 14, 7, 512)   2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 14, 7, 512)   0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 14, 7, 2048)  1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 14, 7, 2048)  8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 14, 7, 2048)  0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 14, 7, 2048)  0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# uncomment for training resnet50\n",
    "#get resnet50\n",
    "model_fn=ResNet50(include_top=False, input_shape=(448,224,3),pooling='avg')\n",
    "#for layer in model_fn.layers:\n",
    "#    layer.trainable = False\n",
    "model_fn.summary()\n",
    "\n",
    "# uncomment for training inceptionv3\n",
    "#model_fn=InceptionV3(include_top=False, input_shape=(448,224,1),pooling='avg')\n",
    "#model_fn.summary()\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(model_fn)\n",
    "#model.add(L.Dense(256,activation='relu'))\n",
    "model.add(L.Dense(2,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-e9e0828763ca>:22: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2121 steps, validate for 606 steps\n",
      "Epoch 1/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.9101 - mean_absolute_error: 0.6688\n",
      "Epoch 00001: val_loss improved from inf to 2.38468, saving model to models/checkpoint_CNN1male\n",
      "WARNING:tensorflow:From /home/eric/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 352s 166ms/step - loss: 0.9100 - mean_absolute_error: 0.6688 - val_loss: 2.3847 - val_mean_absolute_error: 1.1869\n",
      "Epoch 2/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.2689 - mean_absolute_error: 0.4036\n",
      "Epoch 00002: val_loss did not improve from 2.38468\n",
      "2121/2121 [==============================] - 323s 152ms/step - loss: 0.2689 - mean_absolute_error: 0.4036 - val_loss: 189.0971 - val_mean_absolute_error: 12.4115\n",
      "Epoch 3/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.1882 - mean_absolute_error: 0.3369\n",
      "Epoch 00003: val_loss did not improve from 2.38468\n",
      "2121/2121 [==============================] - 324s 153ms/step - loss: 0.1882 - mean_absolute_error: 0.3369 - val_loss: 114.4454 - val_mean_absolute_error: 8.9758\n",
      "Epoch 4/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.1565 - mean_absolute_error: 0.3080\n",
      "Epoch 00004: val_loss did not improve from 2.38468\n",
      "2121/2121 [==============================] - 325s 153ms/step - loss: 0.1565 - mean_absolute_error: 0.3080 - val_loss: 8.4287 - val_mean_absolute_error: 2.2968\n",
      "Epoch 5/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.1148 - mean_absolute_error: 0.2631\n",
      "Epoch 00005: val_loss improved from 2.38468 to 1.62898, saving model to models/checkpoint_CNN1male\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 352s 166ms/step - loss: 0.1147 - mean_absolute_error: 0.2631 - val_loss: 1.6290 - val_mean_absolute_error: 0.8499\n",
      "Epoch 6/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.2370\n",
      "Epoch 00006: val_loss improved from 1.62898 to 0.87218, saving model to models/checkpoint_CNN1male\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 354s 167ms/step - loss: 0.0931 - mean_absolute_error: 0.2369 - val_loss: 0.8722 - val_mean_absolute_error: 0.6438\n",
      "Epoch 7/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.2087\n",
      "Epoch 00007: val_loss improved from 0.87218 to 0.31249, saving model to models/checkpoint_CNN1male\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 355s 167ms/step - loss: 0.0718 - mean_absolute_error: 0.2087 - val_loss: 0.3125 - val_mean_absolute_error: 0.4234\n",
      "Epoch 8/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0572 - mean_absolute_error: 0.1856\n",
      "Epoch 00008: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 156ms/step - loss: 0.0572 - mean_absolute_error: 0.1856 - val_loss: 0.3638 - val_mean_absolute_error: 0.4292\n",
      "Epoch 9/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0488 - mean_absolute_error: 0.1711\n",
      "Epoch 00009: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 155ms/step - loss: 0.0488 - mean_absolute_error: 0.1711 - val_loss: 0.3468 - val_mean_absolute_error: 0.4168\n",
      "Epoch 10/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0403 - mean_absolute_error: 0.1559\n",
      "Epoch 00010: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 156ms/step - loss: 0.0403 - mean_absolute_error: 0.1559 - val_loss: 0.7130 - val_mean_absolute_error: 0.6344\n",
      "Epoch 11/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0359 - mean_absolute_error: 0.1468\n",
      "Epoch 00011: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 156ms/step - loss: 0.0359 - mean_absolute_error: 0.1468 - val_loss: 0.3822 - val_mean_absolute_error: 0.4241\n",
      "Epoch 12/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0318 - mean_absolute_error: 0.1382\n",
      "Epoch 00012: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 156ms/step - loss: 0.0318 - mean_absolute_error: 0.1382 - val_loss: 0.3563 - val_mean_absolute_error: 0.4148\n",
      "Epoch 13/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0100 - mean_absolute_error: 0.0772\n",
      "Epoch 00013: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 329s 155ms/step - loss: 0.0100 - mean_absolute_error: 0.0772 - val_loss: 0.3151 - val_mean_absolute_error: 0.3929\n",
      "Epoch 14/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0055 - mean_absolute_error: 0.0581\n",
      "Epoch 00014: val_loss did not improve from 0.31249\n",
      "2121/2121 [==============================] - 330s 155ms/step - loss: 0.0055 - mean_absolute_error: 0.0581 - val_loss: 0.3204 - val_mean_absolute_error: 0.3948\n",
      "Epoch 15/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0493\n",
      "Epoch 00015: val_loss improved from 0.31249 to 0.31115, saving model to models/checkpoint_CNN1male\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 355s 167ms/step - loss: 0.0040 - mean_absolute_error: 0.0493 - val_loss: 0.3112 - val_mean_absolute_error: 0.3921\n",
      "Epoch 16/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0434\n",
      "Epoch 00016: val_loss did not improve from 0.31115\n",
      "2121/2121 [==============================] - 330s 156ms/step - loss: 0.0031 - mean_absolute_error: 0.0434 - val_loss: 0.3167 - val_mean_absolute_error: 0.3942\n",
      "Epoch 17/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0384\n",
      "Epoch 00017: val_loss improved from 0.31115 to 0.31062, saving model to models/checkpoint_CNN1male\n",
      "INFO:tensorflow:Assets written to: models/checkpoint_CNN1male/assets\n",
      "2121/2121 [==============================] - 354s 167ms/step - loss: 0.0024 - mean_absolute_error: 0.0384 - val_loss: 0.3106 - val_mean_absolute_error: 0.3910\n",
      "Epoch 18/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0351\n",
      "Epoch 00018: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 0.0020 - mean_absolute_error: 0.0351 - val_loss: 0.3260 - val_mean_absolute_error: 0.3944\n",
      "Epoch 19/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0320\n",
      "Epoch 00019: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 151ms/step - loss: 0.0017 - mean_absolute_error: 0.0320 - val_loss: 0.3242 - val_mean_absolute_error: 0.3955\n",
      "Epoch 20/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0293\n",
      "Epoch 00020: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 151ms/step - loss: 0.0014 - mean_absolute_error: 0.0293 - val_loss: 0.3244 - val_mean_absolute_error: 0.3946\n",
      "Epoch 21/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 7.0151e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 00021: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 151ms/step - loss: 7.0157e-04 - mean_absolute_error: 0.0209 - val_loss: 0.3198 - val_mean_absolute_error: 0.3930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 6.0745e-04 - mean_absolute_error: 0.0195\n",
      "Epoch 00022: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 316s 149ms/step - loss: 6.0750e-04 - mean_absolute_error: 0.0195 - val_loss: 0.3192 - val_mean_absolute_error: 0.3925\n",
      "Epoch 23/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 5.6325e-04 - mean_absolute_error: 0.0187\n",
      "Epoch 00023: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 317s 149ms/step - loss: 5.6326e-04 - mean_absolute_error: 0.0187 - val_loss: 0.3204 - val_mean_absolute_error: 0.3930\n",
      "Epoch 24/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 5.3229e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 00024: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 320s 151ms/step - loss: 5.3241e-04 - mean_absolute_error: 0.0183 - val_loss: 0.3198 - val_mean_absolute_error: 0.3930\n",
      "Epoch 25/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 5.0537e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 00025: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 320s 151ms/step - loss: 5.0546e-04 - mean_absolute_error: 0.0178 - val_loss: 0.3204 - val_mean_absolute_error: 0.3934\n",
      "Epoch 26/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.8548e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 00026: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 320s 151ms/step - loss: 4.8563e-04 - mean_absolute_error: 0.0174 - val_loss: 0.3193 - val_mean_absolute_error: 0.3929\n",
      "Epoch 27/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.6327e-04 - mean_absolute_error: 0.0170\n",
      "Epoch 00027: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 4.6334e-04 - mean_absolute_error: 0.0170 - val_loss: 0.3193 - val_mean_absolute_error: 0.3930\n",
      "Epoch 28/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.4353e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 00028: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 4.4353e-04 - mean_absolute_error: 0.0167 - val_loss: 0.3206 - val_mean_absolute_error: 0.3935\n",
      "Epoch 29/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.2635e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 00029: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 322s 152ms/step - loss: 4.2637e-04 - mean_absolute_error: 0.0163 - val_loss: 0.3211 - val_mean_absolute_error: 0.3934\n",
      "Epoch 30/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 4.1013e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00030: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 4.1008e-04 - mean_absolute_error: 0.0160 - val_loss: 0.3210 - val_mean_absolute_error: 0.3929\n",
      "Epoch 31/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.9465e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 00031: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 322s 152ms/step - loss: 3.9465e-04 - mean_absolute_error: 0.0157 - val_loss: 0.3199 - val_mean_absolute_error: 0.3933\n",
      "Epoch 32/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.7793e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00032: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 322s 152ms/step - loss: 3.7801e-04 - mean_absolute_error: 0.0154 - val_loss: 0.3205 - val_mean_absolute_error: 0.3932\n",
      "Epoch 33/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.6394e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 00033: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 3.6410e-04 - mean_absolute_error: 0.0151 - val_loss: 0.3192 - val_mean_absolute_error: 0.3931\n",
      "Epoch 34/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.5069e-04 - mean_absolute_error: 0.0148\n",
      "Epoch 00034: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 151ms/step - loss: 3.5075e-04 - mean_absolute_error: 0.0148 - val_loss: 0.3198 - val_mean_absolute_error: 0.3931\n",
      "Epoch 35/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.3863e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 00035: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 151ms/step - loss: 3.3859e-04 - mean_absolute_error: 0.0145 - val_loss: 0.3210 - val_mean_absolute_error: 0.3943\n",
      "Epoch 36/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.2669e-04 - mean_absolute_error: 0.0143\n",
      "Epoch 00036: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 321s 152ms/step - loss: 3.2672e-04 - mean_absolute_error: 0.0143 - val_loss: 0.3196 - val_mean_absolute_error: 0.3933\n",
      "Epoch 37/50\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 3.1234e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 00037: val_loss did not improve from 0.31062\n",
      "2121/2121 [==============================] - 322s 152ms/step - loss: 3.1237e-04 - mean_absolute_error: 0.0140 - val_loss: 0.3214 - val_mean_absolute_error: 0.3932\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.00001, min_delta=0.001)\n",
    "ckpt=ModelCheckpoint('models/checkpoint_'+notebookname, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.0001)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mean_absolute_error'])\n",
    "\n",
    "# model fit call for all data\n",
    "# history=model.fit(train, train_label, batch_size=32,\n",
    "#                     steps_per_epoch=len(train) / 32, epochs=50)\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                           steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                           validation_data=valid_generator,\n",
    "                           validation_steps=STEP_SIZE_VALID,\n",
    "                           validation_freq=1,\n",
    "                           epochs=50,\n",
    "                           callbacks=[rlr,ckpt,es])\n",
    "# model fit call with validation\n",
    "#history=model.fit(X_train, y_train,validation_data=(X_val,y_val), batch_size=64,\n",
    "#                    steps_per_epoch=len(X_train) / 64,validation_steps=len(X_val)/64, epochs=50,callbacks=[rlr,ckpt,es])\n",
    "\n",
    "# save weights\n",
    "model.save_weights('models/'+notebookname+'.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e82515759ac2>:4: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "606/606 [==============================] - 26s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "predictions=model.predict_generator(test_generator,\n",
    "                                    steps=STEP_SIZE_TEST,\n",
    "                                    verbose = 1)\n",
    "data = {'T1': testdf[str(genderindex[0])],\n",
    "        'T2': testdf[str(genderindex[1])],\n",
    "        'P1': predictions[:,0],\n",
    "        'P2': predictions[:,1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "import csv\n",
    "\n",
    "df.to_csv('results/test_results_'+notebookname+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy'+notebookname)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
